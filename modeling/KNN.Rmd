---
title: "R Notebook"
output: html_notebook
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F, error = F)

library(tidymodels)
library(tidyverse)
```

# KNN Model Setup

```{r}
# model 
knn_model <- nearest_neighbor(
  mode = "classification",
  engine = "kknn",
  neighbors = tune(),
  weight_func = NULL,
  dist_power = NULL
)

# kvals
k_grid <- tibble(neighbors = c(5, 10, 20, 30, 50, 75, 100, 125, 150))
```

# KNN w/ROSE Sampling

Set up data 

```{r}
train_rose <- read_csv("../data/final/train_rose_sampling.csv") %>% 
  janitor::clean_names() %>% 
  mutate(y_bin = as.factor(y_bin))

test <- read_csv("../data/final/test_original_sampling.csv") %>% 
  clean_names %>% 
  mutate(y_bin = as.factor(y_bin))

#stratified cross-validation
rose_cv <- vfold_cv(data = train_rose, v = 5, strata = y_bin)
```


```{r}
# old train/test/cv split
#data_split <- initial_split(data, prop = 3/4)
#data_train <- training(data_split)
#data_test <- testing(data_split)
#data_cv <- vfold_cv(data_train,  v = 3)
```

Run Model 

```{r}
# recipe
rose_hospital_recipe <- recipe(y_bin ~ ., data = train_rose)

# workflow
rose_knn_wf <- workflow() %>% 
          add_model(knn_model) %>% 
          add_recipe(rose_hospital_recipe)

# tuning
rose_knn_tuning <- rose_knn_wf %>%
  tune_grid(
    resamples = rose_cv,
    grid = k_grid,
    control = control_grid(save_pred = TRUE),
    metrics = metric_set(accuracy, roc_auc, sens, spec)
  )
```


Model metrics

```{r}
#model metrics
rose_knn_metrics <- rose_knn_tuning %>% collect_metrics()

rose_knn_metrics <- rose_knn_metrics %>% select(-std_err) %>% 
  pivot_wider(names_from = .metric, values_from = mean)

#find best model based on different metrics
rose_best_accuracy <- rose_knn_metrics %>% filter(accuracy == max(accuracy)) 
rose_best_roc_auc <- rose_knn_metrics %>% filter(roc_auc == max(roc_auc)) 
rose_best_sens <- rose_knn_metrics %>% filter(sens == max(sens))  
rose_best_spec <- rose_knn_metrics %>% filter(spec == max(spec)) 
```


Test error

```{r}
rose_knn_best <- rose_knn_tuning %>% 
  select_best(metric = "sens")

rose_knn_wf <- rose_knn_wf %>%
  finalize_workflow(rose_knn_best)

rose_knn_fit <- fit(rose_knn_wf, train_rose)

rose_knn_preds <- predict(rose_knn_fit, test, type = "prob") %>%
  cbind(actual = test$y_bin) %>% 
  mutate(pred = ifelse(.pred_1 >= 0.5, 1, 0))

rose_knn_preds %>% group_by(actual, pred) %>% summarize(n=n())
```


```{r}
rose_knn_testing_pred <- 
  predict(rose_knn_fit, test) %>% 
  bind_cols(predict(rose_knn_fit, test, type = "prob")) %>% 
  mutate(.pred_class = as.factor(ifelse(.pred_1 >= 0.4, 1, 0))) %>%
  bind_cols(test %>% select(y_bin))

# confusion matrix
rose_knn_testing_pred %>%  
  conf_mat(truth = y_bin, .pred_class)

# sensitivity 
rose_knn_testing_pred %>%  
  sens(truth = y_bin, .pred_class)
```


# KNN w/SMOTE Sampling

Set up data 

```{r}
# read in SMOTE combined sampling (& original sampling)
train_smote <- read_csv("../data/final/train_combined_sampling.csv") %>%
  mutate(y_bin = as.factor(y_bin)) %>% select(-y_bin, everything(), y_bin, -X1)

test <- read_csv("../data/final/test_original_sampling.csv") %>% mutate(y_bin = as.factor(y_bin)) 

#stratified cross-validation=
smote_cv <- vfold_cv(data = train_smote, v = 5, strata = y_bin)
```


Run Model 

```{r}
# recipe
smote_hospital_recipe <- recipe(y_bin ~ ., data = train_smote)

# workflow
smote_knn_wf <- workflow() %>% 
          add_model(knn_model) %>% 
          add_recipe(smote_hospital_recipe)

# tuning
smote_knn_tuning <- smote_knn_wf %>%
  tune_grid(
    resamples = smote_cv,
    grid = k_grid,
    control = control_grid(save_pred = TRUE),
    metrics = metric_set(accuracy, roc_auc, sens, spec)
  )
```


Model metrics

```{r}
#model metrics
smote_knn_metrics <- smote_knn_tuning %>% collect_metrics()

smote_knn_metrics <- smote_knn_metrics %>% select(-std_err) %>% 
  pivot_wider(names_from = .metric, values_from = mean)

#find best model based on different metrics
smote_best_accuracy <- smote_knn_metrics %>% filter(accuracy == max(accuracy)) 
smote_best_roc_auc <- smote_knn_metrics %>% filter(roc_auc == max(roc_auc)) 
smote_best_sens <- smote_knn_metrics %>% filter(sens == max(sens))  
smote_best_spec <- smote_knn_metrics %>% filter(spec == max(spec)) 
```


Test error

```{r}
smote_knn_best <- smote_knn_tuning %>% 
  select_best(metric = "sens")

smote_knn_wf <- smote_knn_wf %>%
  finalize_workflow(rose_knn_best)

smote_knn_fit <- fit(smote_knn_wf, train_smote)

smote_knn_testing_pred <- 
  predict(smote_knn_fit, test) %>% 
  bind_cols(predict(smote_knn_fit, test, type = "prob")) %>% 
  mutate(.pred_class = as.factor(ifelse(.pred_1 >= 0.4, 1, 0))) %>%
  bind_cols(test %>% select(y_bin))

# confusion matrix
smote_knn_testing_pred %>%  
  conf_mat(truth = y_bin, .pred_class)

# sensitivity 
smote_knn_testing_pred %>%  
  sens(truth = y_bin, .pred_class)
```

# Conclusion

ROSE slightly better than SMOTE. 